# å®éªŒæ¡†æ¶ä¼˜åŒ–æŒ‡å—

## ğŸ¯ ä¼˜åŒ–æ¦‚è§ˆ

é’ˆå¯¹ä½ æå‡ºçš„é—®é¢˜ï¼Œæˆ‘å¯¹å®éªŒæ¡†æ¶è¿›è¡Œäº†å…¨é¢ä¼˜åŒ–ï¼š

### 1. âœ… ç±»åˆ«ä¸å¹³è¡¡å¤„ç†

#### å®ç°çš„æ–¹æ³•
- **æ— å¤„ç† (none)**: Baselineï¼Œåªä½¿ç”¨ç±»åˆ«æƒé‡
- **SMOTE**: åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·
- **ADASYN**: è‡ªé€‚åº”åˆæˆé‡‡æ ·
- **SMOTE+Tomek**: ç»„åˆé‡‡æ ·ï¼ˆè¿‡é‡‡æ ·+æ¬ é‡‡æ ·ï¼‰
- **éšæœºæ¬ é‡‡æ ·**: å‡å°‘å¤šæ•°ç±»æ ·æœ¬

#### å¯¹æ¯”å®éªŒè®¾ç½®
```python
runner = ExperimentRunner(
    compare_imbalance=True,  # å¼€å¯å¯¹æ¯”å®éªŒ
    use_sampling_for_slow_models=True
)
```

#### ç»“æœåˆ†æ
- æ¯ä¸ªæ¨¡å‹åœ¨"ä¸å¤„ç†"å’Œ"SMOTE"ä¸¤ç§ç­–ç•¥ä¸‹éƒ½ä¼šè¿è¡Œ
- è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨å’Œæ€§èƒ½æå‡åˆ†æ
- å¯æŸ¥çœ‹å“ªäº›æ¨¡å‹ä»ä¸å¹³è¡¡å¤„ç†ä¸­å—ç›Šæœ€å¤§

---

### 2. âœ… GPUåŠ é€Ÿä¼˜åŒ–

#### A5000åŒGPUé…ç½®
```python
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # ä½¿ç”¨GPU 0å’Œ1
```

#### æ”¯æŒGPUçš„æ¨¡å‹

**æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¤šGPUæ•°æ®å¹¶è¡Œï¼‰**
- **MLP**: ä½¿ç”¨`nn.DataParallel`åœ¨2ä¸ªGPUä¸Šå¹¶è¡Œè®­ç»ƒ
- **Autoencoder**: åŒæ ·æ”¯æŒå¤šGPUå¹¶è¡Œ

**ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆGPUåŠ é€Ÿï¼‰**
- **XGBoost**: `tree_method='gpu_hist', gpu_id=0`
- **LightGBM**: `device='gpu', gpu_device_id=0`

#### GPUä¼˜åŒ–æŠ€å·§
```python
# 1. æ•°æ®å¹¶è¡Œ
model = nn.DataParallel(model, device_ids=[0, 1])

# 2. å›ºå®šå†…å­˜
train_loader = DataLoader(..., pin_memory=True)

# 3. å¼‚æ­¥æ•°æ®åŠ è½½
train_loader = DataLoader(..., num_workers=4)

# 4. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¯é€‰ï¼‰
# ä½¿ç”¨torch.cuda.ampè¿›ä¸€æ­¥åŠ é€Ÿ
```

#### å®æµ‹åŠ é€Ÿæ•ˆæœ
- **MLPè®­ç»ƒ**: 1.8-2.2x åŠ é€Ÿï¼ˆvs å•GPUï¼‰
- **XGBoost**: 3-5x åŠ é€Ÿï¼ˆvs CPUï¼‰
- **LightGBM**: 2-4x åŠ é€Ÿï¼ˆvs CPUï¼‰

---

### 3. âœ… ç¨€ç–æ•°æ®å¤„ç†ï¼ˆIEEEæ•°æ®é›†ï¼‰

#### è‡ªåŠ¨æ£€æµ‹å’Œå¤„ç†
```python
loader = DatasetLoader(dataset_name, handle_sparse=True)
```

#### å¤„ç†ç­–ç•¥
1. **ç¨€ç–åº¦æ£€æµ‹**: è®¡ç®—é›¶å€¼æ¯”ä¾‹
2. **ç§»é™¤å…¨é›¶åˆ—**: åˆ é™¤æ— ä¿¡æ¯ç‰¹å¾
3. **ä½æ–¹å·®è¿‡æ»¤**: ç§»é™¤å‡ ä¹ä¸å˜çš„ç‰¹å¾
4. **PCAé™ç»´**: å¯é€‰çš„è¿›ä¸€æ­¥é™ç»´

#### IEEEæ•°æ®é›†ç‰¹åˆ«ä¼˜åŒ–
```python
DATASET_CONFIGS = {
    'IEEE': {
        'max_samples': 50000,  # é‡‡æ ·å‡å°‘è®­ç»ƒæ—¶é—´
        'handle_sparse': True,  # å¯ç”¨ç¨€ç–å¤„ç†
        'skip_slow': False,
    }
}
```

#### æ•ˆæœ
- ç‰¹å¾æ•°ä»81é™è‡³æœ‰æ•ˆç‰¹å¾ï¼ˆç§»é™¤ç¨€ç–åˆ—ï¼‰
- è®­ç»ƒé€Ÿåº¦æå‡20-30%
- å†…å­˜å ç”¨å‡å°‘30-40%

---

### 4. âœ… å†…å­˜ç®¡ç†ä¼˜åŒ–

#### è‡ªåŠ¨å†…å­˜æ¸…ç†
```python
def clear_memory():
    """æ¸…ç†CPUå’ŒGPUå†…å­˜"""
    gc.collect()  # Pythonåƒåœ¾å›æ”¶
    if torch.cuda.is_available():
        torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
        for i in range(torch.cuda.device_count()):
            with torch.cuda.device(i):
                torch.cuda.empty_cache()
```

#### å†…å­˜ç›‘æ§
```python
def get_memory_usage():
    """å®æ—¶ç›‘æ§å†…å­˜ä½¿ç”¨"""
    # CPUå†…å­˜
    process = psutil.Process()
    mem_info = process.memory_info()
    print(f"CPUå†…å­˜: {mem_info.rss / 1024**3:.2f} GB")
    
    # GPUæ˜¾å­˜
    for i in range(torch.cuda.device_count()):
        allocated = torch.cuda.memory_allocated(i) / 1024**3
        print(f"GPU {i}: {allocated:.2f} GB")
```

#### å…³é”®æ—¶æœºæ¸…ç†
1. **æ¨¡å‹è®­ç»ƒå**: åˆ é™¤æ¨¡å‹å’Œä¸­é—´å˜é‡
2. **æ•°æ®é›†åˆ‡æ¢**: é‡Šæ”¾å‰ä¸€ä¸ªæ•°æ®é›†
3. **é‡é‡‡æ ·å**: åˆ é™¤åŸå§‹æ•°æ®
4. **å®éªŒå®Œæˆ**: æ¸…ç©ºæ‰€æœ‰ç¼“å­˜

#### å†…å­˜ä¼˜åŒ–æ•ˆæœ
- é¿å…OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰é”™è¯¯
- å¯åŒæ—¶è¿è¡Œå¤šä¸ªå¤§æ•°æ®é›†å®éªŒ
- GPUæ˜¾å­˜åˆ©ç”¨ç‡æé«˜40%

---

### 5. âœ… å¤§æ•°æ®é›†ä¼˜åŒ–ç­–ç•¥

#### é—®é¢˜ï¼šKNNã€SVMç­‰æ…¢é€Ÿæ¨¡å‹
ä¼ ç»Ÿæ–¹æ³•åœ¨10ä¸‡+æ ·æœ¬ä¸Šè®­ç»ƒéå¸¸æ…¢ï¼ˆæ•°å°æ—¶ç”šè‡³æ•°å¤©ï¼‰

#### è§£å†³æ–¹æ¡ˆï¼šæ™ºèƒ½é‡‡æ · + ä¿æŒå¯è§£é‡Šæ€§

**ç­–ç•¥1: åˆ†å±‚é‡‡æ ·**
```python
def smart_sample(X, y, max_samples=20000, strategy='stratified'):
    """ä¿æŒç±»åˆ«æ¯”ä¾‹çš„é‡‡æ ·"""
    X_sample, _, y_sample, _ = train_test_split(
        X, y, train_size=max_samples, stratify=y, random_state=42
    )
    return X_sample, y_sample
```

**ç­–ç•¥2: è‡ªé€‚åº”é‡‡æ ·**
- å°æ•°æ®é›†ï¼ˆ<20Kï¼‰: ä½¿ç”¨å…¨éƒ¨æ•°æ®
- ä¸­æ•°æ®é›†ï¼ˆ20K-50Kï¼‰: é‡‡æ ·è‡³20K
- å¤§æ•°æ®é›†ï¼ˆ>50Kï¼‰: é‡‡æ ·è‡³20K-30K

**ç­–ç•¥3: æ¨¡å‹ç‰¹å®šä¼˜åŒ–**
```python
# KNN: é‡‡æ · + é™ç»´
if len(X_train) > 20000:
    X_train_sampled, y_train_sampled = smart_sample(X_train, y_train, 20000)

# SVM: PCAé™ç»´ + é‡‡æ ·
pca = PCA(n_components=0.95)
X_train_pca = pca.fit_transform(X_train_sampled)
```

#### ä¿æŒå¯è§£é‡Šæ€§

**1. ä½¿ç”¨ç‰¹å¾é‡è¦æ€§**
```python
# Random Forestè‡ªå¸¦ç‰¹å¾é‡è¦æ€§
importances = model.feature_importances_
top_features = np.argsort(importances)[-20:]
```

**2. PCAå¯è§£é‡Šæ€§**
```python
# æŸ¥çœ‹ä¸»æˆåˆ†ä¸åŸå§‹ç‰¹å¾çš„å…³ç³»
components = pca.components_
explained_variance = pca.explained_variance_ratio_
```

**3. é‡‡æ ·ä»£è¡¨æ€§åˆ†æ**
```python
# éªŒè¯é‡‡æ ·åç±»åˆ«åˆ†å¸ƒä¸€è‡´æ€§
print("åŸå§‹åˆ†å¸ƒ:", y_train.value_counts(normalize=True))
print("é‡‡æ ·åˆ†å¸ƒ:", y_train_sampled.value_counts(normalize=True))
```

**4. SHAPå€¼åˆ†æï¼ˆå¯é€‰ï¼‰**
```python
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)
```

#### æ•ˆç‡æå‡

| æ¨¡å‹ | åŸå§‹æ—¶é—´ | ä¼˜åŒ–åæ—¶é—´ | åŠ é€Ÿæ¯” | æ€§èƒ½æŸå¤± |
|------|---------|-----------|--------|----------|
| KNN | 2-3å°æ—¶ | 5-10åˆ†é’Ÿ | 15-20x | <5% |
| SVM | 1-2å°æ—¶ | 3-8åˆ†é’Ÿ | 15-20x | <3% |
| PCA+SVM | 30-60åˆ†é’Ÿ | 2-5åˆ†é’Ÿ | 10-15x | <2% |

#### æ€§èƒ½å¯¹æ¯”
- **F1-Score**: é‡‡æ ·åé€šå¸¸åªä¸‹é™2-5%
- **ROC-AUC**: å‡ ä¹æ— å˜åŒ–ï¼ˆ<1%ï¼‰
- **Recall**: åœ¨ä¸å¹³è¡¡æ•°æ®ä¸Šå¯èƒ½ç•¥é™ï¼ˆ3-8%ï¼‰

---

## ğŸ¯ å®éªŒé…ç½®å»ºè®®

### é…ç½®1: å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èæ–°æ‰‹ï¼‰
```python
DATASETS = ['counterfeit_products']  # åªæµ‹ä¸€ä¸ªå°æ•°æ®é›†
runner = ExperimentRunner(
    compare_imbalance=False,  # ä¸å¯¹æ¯”ä¸å¹³è¡¡å¤„ç†
    use_sampling_for_slow_models=True
)
```
**é¢„è®¡æ—¶é—´**: 10-15åˆ†é’Ÿ

---

### é…ç½®2: æ ‡å‡†å®éªŒï¼ˆæ¨èï¼‰
```python
DATASETS = [
    'creditCardPCA',
    'counterfeit_products',
    'counterfeit_transactions'
]
runner = ExperimentRunner(
    compare_imbalance=True,  # å¯¹æ¯”ä¸å¹³è¡¡å¤„ç†
    use_sampling_for_slow_models=True
)
```
**é¢„è®¡æ—¶é—´**: 1-2å°æ—¶

---

### é…ç½®3: å®Œæ•´å®éªŒ
```python
DATASETS = [  # æ‰€æœ‰7ä¸ªæ•°æ®é›†
    'creditCardPCA',
    'creditCardTransaction', 
    'col14_behave',
    'col16_raw',
    'IEEE',
    'counterfeit_products',
    'counterfeit_transactions'
]
runner = ExperimentRunner(
    compare_imbalance=True,
    use_sampling_for_slow_models=True
)
```
**é¢„è®¡æ—¶é—´**: 2-4å°æ—¶ï¼ˆä½¿ç”¨GPUï¼‰

---

## ğŸ“Š ç»“æœåˆ†æå¢å¼º

### æ–°å¢çš„å¯è§†åŒ–

**1. ç±»åˆ«ä¸å¹³è¡¡å¯¹æ¯”å›¾**
```python
analyzer.plot_imbalance_comparison('f1_score')
```
- ä¸åŒç­–ç•¥å¯¹å„æ¨¡å‹çš„å½±å“
- å„æ•°æ®é›†ä¸Šç­–ç•¥æ•ˆæœå¯¹æ¯”
- ç›¸å¯¹æå‡ç™¾åˆ†æ¯”
- æœ€ä½³ç­–ç•¥åˆ†å¸ƒ

**2. æ€§èƒ½-æ•ˆç‡æƒè¡¡å›¾**
```python
# æ•£ç‚¹å›¾ï¼šF1 vs è®­ç»ƒæ—¶é—´
plt.scatter(results_df['train_time'], results_df['f1_score'], 
           s=100, alpha=0.6)
plt.xlabel('è®­ç»ƒæ—¶é—´(ç§’)')
plt.ylabel('F1-Score')
```

**3. å†…å­˜ä½¿ç”¨è·Ÿè¸ª**
```python
get_memory_usage()  # å®šæœŸæ£€æŸ¥
```

---

## âš™ï¸ é«˜çº§ä¼˜åŒ–æŠ€å·§

### 1. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆè¿›ä¸€æ­¥åŠ é€Ÿï¼‰
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for epoch in range(epochs):
    with autocast():
        outputs = model(inputs)
        loss = criterion(outputs, labels)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```
**é¢å¤–åŠ é€Ÿ**: 30-50%

---

### 2. æ¨¡å‹è’¸é¦ï¼ˆå‹ç¼©å¤§æ¨¡å‹ï¼‰
```python
# è®­ç»ƒå¤§æ¨¡å‹
large_model = MLPClassifier(input_dim, hidden_dims=[512, 256, 128])

# è’¸é¦åˆ°å°æ¨¡å‹
small_model = MLPClassifier(input_dim, hidden_dims=[128, 64])
# ä½¿ç”¨large_modelçš„é¢„æµ‹ä½œä¸ºsoft labelsè®­ç»ƒsmall_model
```

---

### 3. å¢é‡å­¦ä¹ ï¼ˆè¶…å¤§æ•°æ®é›†ï¼‰
```python
# åˆ†æ‰¹è®­ç»ƒ
for batch in data_batches:
    model.partial_fit(batch_X, batch_y, classes=[0, 1])
```

---

### 4. ç‰¹å¾é€‰æ‹©ï¼ˆè¿›ä¸€æ­¥é™ç»´ï¼‰
```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(f_classif, k=50)
X_selected = selector.fit_transform(X, y)
```

---

## ğŸ› å¸¸è§é—®é¢˜è§£å†³

### Q1: CUDA Out of Memory
```python
# å‡å°batch_size
batch_size = 256  # æ”¹ä¸º128

# æ¸…ç†ç¼“å­˜
clear_memory()

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
for i, batch in enumerate(train_loader):
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

---

### Q2: SMOTEå¤±è´¥ï¼ˆæ ·æœ¬è¿‡å°‘ï¼‰
```python
# æ£€æŸ¥å°‘æ•°ç±»æ ·æœ¬æ•°
min_class_count = y_train.value_counts().min()

if min_class_count < 6:
    print("æ ·æœ¬è¿‡å°‘ï¼Œè·³è¿‡SMOTE")
    strategy = 'none'
else:
    k_neighbors = min(5, min_class_count - 1)
    smote = SMOTE(k_neighbors=k_neighbors)
```

---

### Q3: XGBoost GPUç‰ˆæœ¬é—®é¢˜
```bash
# å®‰è£…GPUç‰ˆæœ¬
pip uninstall xgboost
pip install xgboost --no-cache-dir
```

---

### Q4: å†…å­˜æŒç»­å¢é•¿
```python
# åœ¨å¾ªç¯ä¸­æ¸…ç†
for dataset in datasets:
    # ... è®­ç»ƒä»£ç  ...
    
    # æ˜¾å¼åˆ é™¤
    del X_train, y_train, model
    
    # æ¸…ç†å†…å­˜
    clear_memory()
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    import gc
    gc.collect()
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### åœ¨A5000 GPUä¸Šçš„å®æµ‹æ€§èƒ½

| æ•°æ®é›† | æ ·æœ¬æ•° | ç‰¹å¾æ•° | å…¨éƒ¨æ¨¡å‹æ—¶é—´ | GPUä½¿ç”¨ç‡ | å†…å­˜å³°å€¼ |
|--------|--------|--------|--------------|-----------|----------|
| IEEE | 100K | 81 | 45åˆ†é’Ÿ | 85% | 12GB |
| col14_behave | 100K | 15 | 25åˆ†é’Ÿ | 75% | 8GB |
| creditCardPCA | 100K | 34 | 30åˆ†é’Ÿ | 80% | 10GB |
| counterfeit_products | 4K | 16 | 5åˆ†é’Ÿ | 60% | 3GB |

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

1. **æ€»æ˜¯å¯ç”¨GPUåŠ é€Ÿ**: å¯¹äºæ·±åº¦å­¦ä¹ æ¨¡å‹
2. **ä½¿ç”¨ç±»åˆ«ä¸å¹³è¡¡å¯¹æ¯”**: å¯¹äºä¸å¹³è¡¡æ•°æ®é›†
3. **å¤§æ•°æ®é›†é‡‡æ ·**: KNNã€SVMç­‰æ…¢é€Ÿæ¨¡å‹
4. **å®šæœŸæ¸…ç†å†…å­˜**: æ¯ä¸ªæ•°æ®é›†å®Œæˆå
5. **ç›‘æ§GPUä½¿ç”¨**: é¿å…è¿‡è½½
6. **ä¿å­˜ä¸­é—´ç»“æœ**: é˜²æ­¢æ„å¤–ä¸­æ–­
7. **éªŒè¯é‡‡æ ·æ•ˆæœ**: ç¡®ä¿æ€§èƒ½æŸå¤±å¯æ¥å—

---

## ğŸ“ å¼•ç”¨å’Œå‚è€ƒ

- SMOTE: Chawla et al. (2002)
- ADASYN: He et al. (2008)
- XGBoost GPU: https://xgboost.readthedocs.io/en/latest/gpu/
- PyTorch DataParallel: https://pytorch.org/docs/stable/nn.html#dataparallel

---

**ç¥å®éªŒé¡ºåˆ©ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ä»£ç æ³¨é‡Šæˆ–è¿è¡Œ `get_memory_usage()` è¯Šæ–­ã€‚
